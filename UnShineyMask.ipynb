{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "cNyzbt5_Ibaa",
    "outputId": "a83f9831-6497-4f4b-f11d-95cd345849b0"
   },
   "outputs": [],
   "source": [
    "#!pip install tensorflow-gpu\n",
    "!pip3 install matplotlib\n",
    "!pip3 install keras\n",
    "#!dir |more\n",
    "#!pip install google.coLab\n",
    "#from google.coLab import drive\n",
    "#import google as ggl\n",
    "#print(ggl.__doc__)\n",
    "#drive.mount('/content/drive')\n",
    "#!unzip \"/content/drive/My Drive/Class 1.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "id": "ktH-4AIM2MbQ",
    "outputId": "0ac21ebd-526c-4708-a6df-18ab19b605a3"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#%matplotlib notebook\n",
    "\n",
    "import numpy as np\n",
    "import glob\n",
    "import pathlib\n",
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices()) # list of DeviceAttributes\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "import timeit\n",
    "imgspec = {}\n",
    "imgspec[\"size\"]= 64\n",
    "imgspec[\"channels\"]=1\n",
    "imgspec[\"len\"] = (imgspec[\"size\"]**2)*imgspec[\"channels\"]\n",
    "imgspec[\"descArr\"]=[imgspec[\"size\"],imgspec[\"size\"],imgspec[\"channels\"]]\n",
    "print(imgspec)\n",
    "print(imgspec[\"descArr\"])\n",
    "imgspec[\"descArr\"][0:2]\n",
    "\n",
    "device = 'DML'\n",
    "#device='/device:XLA_CPU:0'\n",
    "#device = '/cpu'\n",
    "floattype = tf.float32\n",
    "tf.keras.backend.set_floatx('float32')\n",
    "\n",
    "#local_device_protos = tf.python.client.device_lib.list_local_devices()\n",
    "#print([x.name for x in local_device_protos])\n",
    "\n",
    "####################\n",
    "num=5990/1\n",
    "sets = [1,1,1,1,1,1]\n",
    "###################\n",
    "#sets = ['1','4']\n",
    "def boolActivation(x):\n",
    "    return x>.5\n",
    "\n",
    "def SaveImgOut(tensor,idx,execute=True):\n",
    "    #print (type(y_test))\n",
    "    with tf.device(device):\n",
    "      #print(tensor.shape)\n",
    "      #img = tf.reshape(X_test[0],[imgspec[\"len\"]])\n",
    "      \n",
    "      #img = np.array([img.numpy()])\n",
    "      #img = img.numpy()\n",
    "      #print(tensor)\n",
    "      if execute:        \n",
    "        #tensor = tf.reshape(tensor,imgspec[\"descArr\"])\n",
    "        tensor = tf.reshape(tensor,[1,imgspec[\"len\"]])\n",
    "        tensor=model(tensor)\n",
    "        \n",
    "      #print (tensor)\n",
    "      img=tf.reshape(tensor,imgspec[\"descArr\"]).numpy()\n",
    "      tf.keras.preprocessing.image.save_img('./'+str(idx)+'.png',img)\n",
    "        \n",
    "def getDataSet(num,cls=['1']):\n",
    "\n",
    "    def decode_img(img):        \n",
    "        #print(\"decode\")\n",
    "        with tf.device(device):\n",
    "            img= tf.keras.preprocessing.image.load_img(img,color_mode=\"grayscale\")\n",
    "            img = img.resize((imgspec[\"size\"], imgspec[\"size\"]), Image.LANCZOS )\n",
    "            img = tf.keras.preprocessing.image.img_to_array(img)\n",
    "            \n",
    "            #img =tf.image.decode_png(img, channels=imgspec[\"channels\"],dtype=tf.uint8)   \n",
    "            #print(img.shape)\n",
    "            #img = tf.reshape(img,[imgspec[\"len\"] ])\n",
    "            #print(img.shape)\n",
    "            #print(type(img))\n",
    "            #img=tf.keras.preprocessing.image.resize\n",
    "            img = tf.image.convert_image_dtype(img, floattype)\n",
    "            \n",
    "            #img = tf.constant( img) \n",
    "            #print (img)\n",
    "            \n",
    "            img=tf.reshape (img,[4096])\n",
    "            #print(img.shape)\n",
    "            #print(img[0].shape)\n",
    "            return img\n",
    "\n",
    "    def LoadOne(pathpair):\n",
    "        # print(pathpair)\n",
    "        # label = get_label(file_path)\n",
    "        # load the raw data from the file as a string\n",
    "        label = pathpair[1][0]\n",
    "        img = pathpair[0][0]\n",
    "\n",
    "        with tf.device(device):\n",
    "            label = decode_img(label)\n",
    "            img   = decode_img(img)\n",
    "            #print (img)\n",
    "            return [img, label]\n",
    "\n",
    "\n",
    "    \n",
    "    dataset=[]\n",
    "    print(cls)\n",
    "    numClasses=len(cls)\n",
    "    for iclass in range(numClasses):\n",
    "        print('Processing class '+str(iclass)+', weight: '+str(cls[iclass]))\n",
    "        data_dir = pathlib.Path('./Mask/Class '+str(iclass+1))\n",
    "        print('searching: '+str(data_dir))\n",
    "        files = list(data_dir.glob('*.png'))\n",
    "        print(len(files))\n",
    "\n",
    "        data = [ [[str(i)],[str(i).replace(\"x.png\",\"y.png\")]]  for i in files if str(i).find(\"y.png\")==-1 ]\n",
    "        print('found files: ',len(data))\n",
    "        \n",
    "        npcls=np.array(cls)\n",
    "        #print(npcls)\n",
    "        classWeight= cls[iclass]/npcls.sum()\n",
    "        print('perWeight: '+str(classWeight))\n",
    "        needed = int(classWeight*(num))\n",
    "        print('Needed: ',needed)\n",
    "        for i in range(needed):\n",
    "            #print(i)\n",
    "            n=LoadOne(data[i])\n",
    "            dataset.append(n)\n",
    "            #Xtrain.append(tf.reshape(n[0],[imgspec[\"len\"]]))\n",
    "            #ytrain.append(tf.reshape(n[1],[imgspec[\"len\"]]))\n",
    "            \n",
    "        #labeled_ds = tf.data.Dataset.from_generator(Gen,(tf.float32,tf.float32))\n",
    "    #dataset= tf.data.Dataset.from_tensor_slices(dataset)\n",
    "    return tf.data.Dataset.from_tensor_slices(dataset),len(dataset)\n",
    "\n",
    "X_train=[]\n",
    "y_train=[]\n",
    "\n",
    "tsize = int(min(100,int(num*(3/4.0))))\n",
    "\n",
    "allData,ln= getDataSet(num,sets)\n",
    "allData= allData.shuffle(ln)\n",
    "\n",
    "#print(len(allData))\n",
    "#print(num,tsize,len(allData))\n",
    "print(np.array(allData).shape)\n",
    "for record in allData:\n",
    "    #print(record[0])\n",
    "    X_train.append(record[0])\n",
    "    y_train.append(record[1])\n",
    "    \n",
    "print(len(X_train))\n",
    "print(len(y_train))\n",
    "\n",
    "#X_train = allData[0][0:num-tsize]\n",
    "#y_train = allData[1][0:num-tsize]\n",
    "\n",
    "#X_test = allData[0][num-tsize:num]\n",
    "#y_test = allData[1][num-tsize:num]\n",
    "\n",
    "SaveImgOut(X_train[10],0,execute=False)\n",
    "SaveImgOut(y_train[10],1,execute=False)\n",
    "\n",
    "#print('x')\n",
    "#print(X_test)   \n",
    "#print('y')\n",
    "#print(y_test)   \n",
    "#for image, label in thing:\n",
    "    #print (\"loop\")\n",
    "    #print(\"Image shape: \", image.numpy().shape)\n",
    "    #print(\"Label: \", label.numpy().shape)\n",
    "    #plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hsobFDAC2MbV"
   },
   "outputs": [],
   "source": [
    "def MakeModel(u,t):\n",
    "    is2d=False\n",
    "    with tf.device(device):\n",
    "        model = tf.keras.models.Sequential()\n",
    "        #model.add(tf.keras.layers.Dense(units=256 , activation='relu' ,input_shape=(256*256*3,)))\n",
    "        #model.add(tf.keras.layers.Dense(units=16 , activation='relu'))\n",
    "        #model.add(tf.keras.layers.Dense(units=32 , activation='relu',input_shape=(16,)))\n",
    "        #model.add(tf.keras.layers.Dense(units=64 , activation='relu',input_shape=(32,)))\n",
    "        #model.add(tf.keras.layers.Dense(units=196608 , activation='hard_sigmoid',input_shape=(64,)))    \n",
    "        #model.add(tf.keras.layers.Dense(units=imgspec[\"len\"] , activation='relu'))\n",
    "\n",
    "\n",
    "        for i in range(u[0]):\n",
    "            \n",
    "            if t[i]=='de' and is2d:                \n",
    "                model.add(tf.keras.layers.Flatten())\n",
    "                \n",
    "            if t[i]=='de':\n",
    "                model.add(tf.keras.layers.Dense(units=u[1] , activation=tf.keras.activations.selu))\n",
    "                print('Adding DENSE layer: Units='+str(u[1]))\n",
    "            \n",
    "            if t[i][:2]=='co' and not is2d:\n",
    "                model.add(tf.keras.layers.Reshape((64,64,1)))\n",
    "                is2d=True\n",
    "                \n",
    "            if t[i][:2]=='co' and is2d:\n",
    "                kernel = int(t[i][2])\n",
    "                kernel= (kernel,kernel)\n",
    "                \n",
    "                model.add(tf.keras.layers.Conv2D(1,kernel, activation=tf.keras.activations.selu))\n",
    "                print('Adding CONV2D layer: Units='+str(u[1]))\n",
    "            \n",
    "            if t[i]=='po':\n",
    "                pass\n",
    "\n",
    "\n",
    "\n",
    "        model.add(tf.keras.layers.Dense(units=imgspec[\"len\"] , activation= 'sigmoid'))\n",
    "        return model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1PyN_Rym2MbZ"
   },
   "outputs": [],
   "source": [
    "models=[]\n",
    "models.append(MakeModel( [8,128] ,['de']*8) ) \n",
    "models.append(MakeModel( [8,128] ,['co3']*1+['de']*7) ) \n",
    "models.append(MakeModel( [8,128] ,['co3']*4+['de']*4) ) \n",
    "#models.append(MakeModel( [1,128] ,['de']*1) ) \n",
    "\n",
    "\n",
    "for model in models:\n",
    "    model.compile(optimizer= tf.keras.optimizers.Adam(learning_rate=.00025),\n",
    "              loss=tf.losses.absolute_difference )\n",
    "    \n",
    "print(len(models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "m1b8ttuV2Mbc",
    "outputId": "aeef0bc2-3567-4f17-ffc8-a206f2aeb564"
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "#print(model.optimizer.variables())\n",
    "\n",
    "with tf.device(device):\n",
    "    X_train = tf.convert_to_tensor(X_train)\n",
    "    y_train = tf.convert_to_tensor(y_train)\n",
    "    X_train=tf.cast(X_train, floattype)\n",
    "    y_train=tf.cast(y_train, floattype)\n",
    "\n",
    "with tf.device(device):\n",
    "   \n",
    "    #SaveImgOut(X_train[0],i,execute = False)\n",
    "    #SaveImgOut(X_train[0],i+100000,execute = True)\n",
    "    \n",
    "    #SaveImgOut(y_test[0],123123,execute=False)\n",
    "    \n",
    "    lossHist=[[]]*len(models)\n",
    "    valHist =[[]]*len(models)\n",
    "    \n",
    "    print(lossHist)\n",
    "    print(valHist)\n",
    "    while True:\n",
    "        for modelIndex, model in enumerate(models):\n",
    "            #model.summary()\n",
    "            #en=np.min([i+1,5])    \n",
    "            en=1\n",
    "            print('modelidx',modelIndex)\n",
    "            \n",
    "            import time\n",
    "\n",
    "            t_end = time.time() + 5\n",
    "            while time.time() < t_end:\n",
    "                history=[]\n",
    "                #print('x.shape:',X_train.shape)\n",
    "                #print('y.shape:',y_train.shape)\n",
    "                #print(X_train[0].shape)\n",
    "                #print(y_train[0].shape)\n",
    "                #print(type(X_train[0]))\n",
    "                history = model.fit(X_train,y_train,validation_split=.5,verbose=1,\n",
    "                                    batch_size=40,shuffle=False)\n",
    "                curLoss = history.history[\"loss\"]\n",
    "                curVal  = history.history[\"val_loss\"]\n",
    "                lossHist[modelIndex]=lossHist[modelIndex]+[curLoss]\n",
    "                valHist [modelIndex]=valHist[modelIndex]+[curVal]\n",
    "\n",
    "            print ('Model: '+str(modelIndex))\n",
    "            #print(lossHist[modelIndex])\n",
    "            \n",
    "            #historys[modelIndex].append(overallHist)\n",
    "\n",
    "            \n",
    "\n",
    "            #print(history.history)\n",
    "            print(str(0)+\"curLoss: \"+ str(curLoss))\n",
    "            print(str(0)+\"curVal: \" + str(curVal))\n",
    "\n",
    "            imgidx = 10\n",
    "            testT = X_train[imgidx]\n",
    "            print(type(testT))\n",
    "            print(testT)\n",
    "            \n",
    "            #result = model.call(testT)\n",
    "            result = model(tf.reshape(testT,[1,imgspec[\"len\"]]))\n",
    "            result = model.predict(result)\n",
    "            \n",
    "\n",
    "            img1 = tf.reshape(result,imgspec[\"descArr\"] )\n",
    "            img2 = tf.reshape(X_train[imgidx],imgspec[\"descArr\"])\n",
    "            img3 = tf.reshape(y_train[imgidx],imgspec[\"descArr\"])\n",
    "\n",
    "            img1=tf.concat(values=[img1,img2,img3],axis=1)\n",
    "\n",
    "\n",
    "            fig,ax = plt.subplots(1,1)\n",
    "            #print(dir(fig))\n",
    "            fig.set_figwidth(10)\n",
    "            ax.imshow(img1,interpolation='nearest')\n",
    "            #plt.show()\n",
    "\n",
    "           \n",
    "        \n",
    "            #print (overallHist[0])\n",
    "            #print (overallHist[1])\n",
    "            #print(historys)\n",
    "            #print(historys[0])\n",
    "        clear_output(wait=True)    \n",
    "        fig2,ax = plt.subplots(1,1)        \n",
    "        fig2.set_figwidth(10)\n",
    "\n",
    "        for i in range(len(lossHist)):            \n",
    "            print ('Model: '+str(i))\n",
    "            \n",
    "            #l = historys[i][0]\n",
    "            #v = historys[i][1]\n",
    "            ax.plot(lossHist[i][5:],label=str(i)+\" Loss\",linestyle='dashed')\n",
    "            ax.plot(valHist [i][5:],label=str(i)+\" Validation\")\n",
    "            ax.legend()\n",
    "            #ax.plot(v)\n",
    "\n",
    "        plt.show()  \n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "id": "UtCh7aBa2Mbe",
    "outputId": "079b8277-7970-4a69-eb7b-013a8b684b46"
   },
   "outputs": [],
   "source": [
    "#print (y_test.numpy())\n",
    "#print (y_train)\n",
    "with tf.device(\"/gpu:0\"):\n",
    "    X_test = tf.convert_to_tensor(X_test)\n",
    "    y_test = tf.convert_to_tensor(y_test)\n",
    "    test_loss = model.evaluate(X_test.numpy(), y_test.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WtOWTqYr2Mbg"
   },
   "outputs": [],
   "source": [
    "GetImgOut(X_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BWOc_Urr2Mbj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oJ2-eqn52Mbm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 519
    },
    "id": "9MFRprYj2Mbp",
    "outputId": "662e8be1-2350-49b4-b62c-0650f5b787ee"
   },
   "outputs": [],
   "source": [
    "a=np.array([X_test[3]])\n",
    "with tf.device(\"/gpu:0\"):\n",
    "    b=model.call(a)\n",
    "with tf.device(\"/gpu:0\"):\n",
    "    plt.imshow(tf.reshape(a,))\n",
    "    plt.show()\n",
    "with tf.device(\"/gpu:0\"):\n",
    "    plt.imshow(tf.reshape(b,))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268
    },
    "id": "VRV9AzaJ2Mbs",
    "outputId": "bae39f3d-ad5d-488c-cb14-ed3d55ae90b3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fzuh5izQ2Mbv"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ApM6A8kY2Mby"
   },
   "outputs": [],
   "source": [
    "model.save(\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9i5nN3iz2Mb1"
   },
   "outputs": [],
   "source": [
    "#\n",
    "import tensorflow as tf\n",
    "model =tf.keras.models.load_model(\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "UnShiney-Copy1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
